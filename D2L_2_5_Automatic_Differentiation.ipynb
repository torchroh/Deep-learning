{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOygjS3ejjhffapA/XaNGoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/torchroh/Deep-learning/blob/main/D2L_2_5_Automatic_Differentiation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5 Automatic Differentiation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "when we pass data through each successive function, the framework builds a computational graph(how each value depends on others)\n",
        "\n",
        "automatic differentiation은 이 그래프를 역으로 실행함.\n",
        "\n",
        "이러한 방식으로 체인 규칙을 적용하는 알고리즘을 backpropagation이라고 한다."
      ],
      "metadata": {
        "id": "Y_HHf_mTu-uL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MItI2xQst8oV"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5.1 Simple Function\n",
        "\n",
        "---\n",
        "![image.png](data:image/png;base64,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)를 미분하고자 한다.\n",
        "\n",
        "시작: assign x an initial value\n"
      ],
      "metadata": {
        "id": "IVkxTtfvwvCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(4.0)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAGV3e01xE8Q",
        "outputId": "4e9e13f0-2aa4-4b5b-a26a-8ac404b3c7dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "x에 대하여 y의 gradient를 계산하기에 앞서, gradient를 저장할 장소가 필요하다.\n",
        "\n",
        "딥러닝에서는 연속적으로 파생되는 계산을 하는 경우가 많기 때문에 매번 새로운 메모리를 할당하는 것은 주로 피한다.\n",
        "\n",
        "scalar-valued function의 x(vector)에 대한 gradient는 vector-valued한 모양이다. (x와 같음)"
      ],
      "metadata": {
        "id": "LAtTnLWBxK6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also create x = torch.arange(4.0, requires_grad=True)\n",
        "x.requires_grad_(True)\n",
        "x.grad  # The gradient is None by default"
      ],
      "metadata": {
        "id": "htuZfXTvyZkL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "x = tensor([0., 1., 2., 3.]) 였으므로\n",
        "\n",
        "y = 2 * (0^2 + 1^2 + 2^2 + 3^2) = 28"
      ],
      "metadata": {
        "id": "G4tzuNrV0W_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = 2 * torch.dot(x, x)\n",
        "y, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yhQMIe50V1T",
        "outputId": "a9f093ed-2638-4072-ff15-9930bbec2e88"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(28., grad_fn=<MulBackward0>),\n",
              " tensor([0., 1., 2., 3.], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDJvrqE65dNh",
        "outputId": "ec350473-4762-4d74-dbc0-73fd0a54da40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0., 16., 32., 48.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "??????? 나 이거 처음에는 0,4,8,12였다가 0,8,16,24였다가 지금은 0,16,32,48됨..."
      ],
      "metadata": {
        "id": "QJPLmOTK1XLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad == 4 * x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "layjVH4w1W0b",
        "outputId": "7a2ddabd-db16-4654-ef95-c6e71031759e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()  # Reset the gradient 기울기 초기화\n",
        "y = x.sum()\n",
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0-gAHK75vkZ",
        "outputId": "f77ee980-300a-44f1-d1a1-e577ef88c01b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5.2 Backward of Non-Scalar Variables\n",
        "\n",
        "---\n",
        "most natural representation of the derivative of y(vector) with respect to a vextor x is a matrix called Jacobian.\n",
        "\n",
        "It contains partial derivatives of each component of y with respect to each component of x.\n"
      ],
      "metadata": {
        "id": "Vo0vQHfO62hM"
      }
    }
  ]
}